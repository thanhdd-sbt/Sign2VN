# Sign2VN - Chuyá»ƒn Äá»•i NgÃ´n Ngá»¯ KÃ½ Hiá»‡u Sang Tiáº¿ng Viá»‡t

Há»‡ thá»‘ng AI sá»­ dá»¥ng Deep Learning (CNN + LSTM + Seq2Seq with Attention) Ä‘á»ƒ nháº­n diá»‡n ngÃ´n ngá»¯ kÃ½ hiá»‡u tá»« video vÃ  chuyá»ƒn Ä‘á»•i thÃ nh vÄƒn báº£n tiáº¿ng Viá»‡t tá»± nhiÃªn.

## ğŸ“‹ Má»¥c Lá»¥c

- [TÃ­nh NÄƒng](#-tÃ­nh-nÄƒng)
- [Kiáº¿n TrÃºc Model](#-kiáº¿n-trÃºc-model)
- [YÃªu Cáº§u Há»‡ Thá»‘ng](#-yÃªu-cáº§u-há»‡-thá»‘ng)
- [CÃ i Äáº·t](#-cÃ i-Ä‘áº·t)
- [Cáº¥u TrÃºc Dá»¯ Liá»‡u](#-cáº¥u-trÃºc-dá»¯-liá»‡u)
- [Sá»­ Dá»¥ng](#-sá»­-dá»¥ng)
- [Cáº¥u HÃ¬nh](#-cáº¥u-hÃ¬nh)
- [Káº¿t Quáº£](#-káº¿t-quáº£)
- [Tips & Best Practices](#-tips--best-practices)

## âœ¨ TÃ­nh NÄƒng

- âœ… **Training tá»« Ä‘áº§u** hoáº·c **resume** tá»« checkpoint
- âœ… **Seq2Seq vá»›i Attention** Ä‘á»ƒ táº¡o cÃ¢u tiáº¿ng Viá»‡t tá»± nhiÃªn
- âœ… **Data augmentation**: Gaussian noise, time warping, horizontal flip
- âœ… **Early stopping** vÃ  **learning rate scheduling**
- âœ… **Metrics Ä‘áº§y Ä‘á»§**: Loss, Accuracy, BLEU score
- âœ… **Inference** tá»« video má»›i hoáº·c file .npy
- âœ… **Batch prediction** cho nhiá»u files
- âœ… **Visualization** training history
- âœ… **Checkpointing** tá»± Ä‘á»™ng

## ğŸ—ï¸ Kiáº¿n TrÃºc Model

```
Input Video â†’ MediaPipe Landmarks â†’ Model â†’ Vietnamese Text

Model Architecture:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Input: Landmarks (T, 543*3)                            â”‚
â”‚     â†“                                                    â”‚
â”‚  Spatial Encoder (CNN)                                  â”‚
â”‚     - Conv1D layers vá»›i BatchNorm                       â”‚
â”‚     - Extract spatial features tá»« landmarks             â”‚
â”‚     â†“                                                    â”‚
â”‚  Temporal Encoder (Bidirectional LSTM)                  â”‚
â”‚     - 2 layers LSTM                                     â”‚
â”‚     - Capture temporal dependencies                     â”‚
â”‚     â†“                                                    â”‚
â”‚  Seq2Seq Decoder vá»›i Attention                          â”‚
â”‚     - Bahdanau Attention mechanism                      â”‚
â”‚     - LSTM decoder vá»›i teacher forcing                  â”‚
â”‚     - Embedding layer cho output tokens                 â”‚
â”‚     â†“                                                    â”‚
â”‚  Output: Vietnamese Text                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components Chi Tiáº¿t:

1. **Spatial Encoder (CNN)**:
   - Input: `(batch, seq_len, 543*3)` - landmarks tá»« MediaPipe
   - Conv1D layers: `[64, 128, 256]` filters
   - BatchNorm vÃ  Dropout cho regularization
   - Output: `(batch, seq_len, 256)` spatial features

2. **Temporal Encoder (Bidirectional LSTM)**:
   - Input: Spatial features
   - 2-layer Bi-LSTM vá»›i 512 hidden units
   - Output: `(batch, seq_len, 1024)` temporal features

3. **Attention Mechanism**:
   - Bahdanau attention Ä‘á»ƒ focus vÃ o relevant frames
   - Attention dimension: 256
   - Dynamic weighting cá»§a encoder outputs

4. **Seq2Seq Decoder**:
   - Embedding layer: 256 dimensions
   - LSTM decoder: 512 hidden units
   - Teacher forcing during training
   - Greedy decoding during inference

## ğŸ’» YÃªu Cáº§u Há»‡ Thá»‘ng

- Python 3.8+
- CUDA-capable GPU (khuyáº¿n nghá»‹, cÃ³ thá»ƒ cháº¡y CPU nhÆ°ng cháº­m)
- Google Colab (khuyáº¿n nghá»‹ cho training)
- Google Drive vá»›i Ã­t nháº¥t 5GB trá»‘ng

## ğŸ“¦ CÃ i Äáº·t

### 1. TrÃªn Google Colab (Khuyáº¿n Nghá»‹)

```python
# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Clone repository hoáº·c upload files
!git clone https://github.com/your-repo/sign2vn.git
# Hoáº·c upload cÃ¡c files .py vÃ o Colab

# CÃ i Ä‘áº·t dependencies
!pip install -r requirements.txt

# Download NLTK data
import nltk
nltk.download('punkt')
```

### 2. Local Installation

```bash
# Clone repository
git clone https://github.com/your-repo/sign2vn.git
cd sign2vn

# Táº¡o virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# hoáº·c
venv\Scripts\activate  # Windows

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt

# Download NLTK data
python -c "import nltk; nltk.download('punkt')"
```

## ğŸ“‚ Cáº¥u TrÃºc Dá»¯ Liá»‡u

Dá»¯ liá»‡u cáº§n Ä‘Æ°á»£c tá»• chá»©c nhÆ° sau trÃªn Google Drive:

```
MyDrive/Sign2VN/
â”œâ”€â”€ meta.csv                    # Metadata file
â”œâ”€â”€ work/
â”‚   â””â”€â”€ landmarks/              # ThÆ° má»¥c chá»©a file .npy
â”‚       â”œâ”€â”€ video1.npy
â”‚       â”œâ”€â”€ video2.npy
â”‚       â””â”€â”€ ...
â”œâ”€â”€ checkpoints/                # Sáº½ Ä‘Æ°á»£c táº¡o tá»± Ä‘á»™ng
â”‚   â”œâ”€â”€ best_model.pt
â”‚   â”œâ”€â”€ latest_checkpoint.pt
â”‚   â”œâ”€â”€ tokenizer.pkl
â”‚   â””â”€â”€ training_history.json
â””â”€â”€ logs/                       # Logs (optional)
```

### Format cá»§a `meta.csv`:

```csv
npy,label,label_vi,orig_name,signer
/path/to/file1.npy,LABEL1,tiáº¿ng viá»‡t 1,video1.mp4,UNKNOWN
/path/to/file2.npy,LABEL2,tiáº¿ng viá»‡t 2,video2.mp4,UNKNOWN
```

### Format cá»§a file `.npy`:

- Shape: `(num_frames, 543*3)`
- `543` landmarks = 33 pose + 21 left_hand + 21 right_hand + 468 face
- Má»—i landmark cÃ³ 3 coordinates: `(x, y, z)`

## ğŸš€ Sá»­ Dá»¥ng

### 1. Training Model

#### Sá»­ dá»¥ng Colab Notebook (Dá»… nháº¥t):

1. Upload `Sign2VN_Training.ipynb` lÃªn Google Colab
2. Mount Google Drive
3. Cháº¡y cÃ¡c cells theo thá»© tá»±

#### Sá»­ dá»¥ng Command Line:

```bash
# Training tá»« Ä‘áº§u
python train.py \
    --num_epochs 100 \
    --batch_size 16 \
    --learning_rate 0.001 \
    --test

# Resume tá»« checkpoint
python train.py \
    --resume_from /path/to/checkpoint.pt \
    --num_epochs 100

# Custom settings
python train.py \
    --num_epochs 50 \
    --batch_size 8 \
    --learning_rate 0.0005 \
    --checkpoint_dir /path/to/checkpoints \
    --test
```

#### Parameters:

- `--num_epochs`: Sá»‘ epochs training (default: 100)
- `--batch_size`: Batch size (default: 16)
- `--learning_rate`: Learning rate (default: 0.001)
- `--checkpoint_dir`: ThÆ° má»¥c lÆ°u checkpoints
- `--resume_from`: Path Ä‘áº¿n checkpoint Ä‘á»ƒ resume
- `--test`: Cháº¡y test sau khi training xong
- `--seed`: Random seed (default: 42)

### 2. Inference - Dá»± ÄoÃ¡n

#### Tá»« file .npy:

```bash
python inference.py \
    --npy_path /path/to/landmarks.npy \
    --checkpoint /path/to/best_model.pt \
    --tokenizer /path/to/tokenizer.pkl
```

#### Tá»« video (sáº½ tá»± Ä‘á»™ng extract landmarks):

```bash
python inference.py \
    --video_path /path/to/video.mp4 \
    --save_npy \
    --checkpoint /path/to/best_model.pt \
    --tokenizer /path/to/tokenizer.pkl
```

#### Batch prediction:

```bash
python inference.py \
    --folder_path /path/to/folder \
    --file_extension .npy \
    --output predictions.json \
    --checkpoint /path/to/best_model.pt \
    --tokenizer /path/to/tokenizer.pkl
```

#### Sá»­ dá»¥ng Python API:

```python
from inference import SignLanguagePredictor

# Khá»Ÿi táº¡o predictor
predictor = SignLanguagePredictor(
    checkpoint_path="/path/to/best_model.pt",
    tokenizer_path="/path/to/tokenizer.pkl"
)

# Dá»± Ä‘oÃ¡n tá»« .npy
result = predictor.predict_from_npy("landmarks.npy")
print(f"Prediction: {result['text']}")

# Dá»± Ä‘oÃ¡n tá»« video
result = predictor.predict_from_video("video.mp4", save_npy=True)
print(f"Prediction: {result['text']}")

# Batch prediction
results = predictor.batch_predict_from_folder(
    folder_path="/path/to/folder",
    file_extension=".npy"
)
```

### 3. Visualization

```python
import json
import matplotlib.pyplot as plt

# Load training history
with open('checkpoints/training_history.json', 'r') as f:
    history = json.load(f)

# Plot loss
plt.figure(figsize=(10, 5))
plt.plot(history['train_loss'], label='Train')
plt.plot(history['val_loss'], label='Validation')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Plot accuracy
plt.figure(figsize=(10, 5))
plt.plot(history['train_acc'], label='Train')
plt.plot(history['val_acc'], label='Validation')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()
```

## âš™ï¸ Cáº¥u HÃ¬nh

Táº¥t cáº£ cáº¥u hÃ¬nh Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trong `config.py`. CÃ¡c tham sá»‘ quan trá»ng:

### Model Hyperparameters:

```python
# CNN
CNN_FILTERS = [64, 128, 256]
CNN_KERNEL_SIZE = 3

# LSTM
LSTM_UNITS = 512
LSTM_LAYERS = 2

# Seq2Seq
ENCODER_HIDDEN_DIM = 512
DECODER_HIDDEN_DIM = 512
ATTENTION_DIM = 256
EMBEDDING_DIM = 256

# Regularization
DROPOUT_RATE = 0.3
```

### Training Settings:

```python
BATCH_SIZE = 16
LEARNING_RATE = 0.001
NUM_EPOCHS = 100
VALIDATION_SPLIT = 0.15
TEST_SPLIT = 0.15
EARLY_STOPPING_PATIENCE = 15
REDUCE_LR_PATIENCE = 7
```

### Data Augmentation:

```python
USE_AUGMENTATION = True
AUGMENTATION_PROB = 0.3
NOISE_SCALE = 0.01
TIME_WARPING_PARAM = 0.2
```

## ğŸ“Š Káº¿t Quáº£

Model Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ báº±ng cÃ¡c metrics:

- **Loss**: Cross-entropy loss
- **Accuracy**: Token-level accuracy (bá» qua padding)
- **BLEU Score**: ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng translation

### VÃ­ dá»¥ káº¿t quáº£:

```
Test Results:
  Loss: 0.8234
  Accuracy: 0.8567
  BLEU Score: 0.7123

Sample Predictions:
1. Target:     xin chÃ o báº¡n
   Prediction: xin chÃ o báº¡n

2. Target:     tÃ´i yÃªu viá»‡t nam
   Prediction: tÃ´i yÃªu viá»‡t nam

3. Target:     cáº£m Æ¡n ráº¥t nhiá»u
   Prediction: cáº£m Æ¡n ráº¥t nhiá»u
```

## ğŸ’¡ Tips & Best Practices

### 1. Data Preparation:

- âœ… Äáº£m báº£o landmarks Ä‘Æ°á»£c extract Ä‘Ãºng báº±ng MediaPipe
- âœ… Chuáº©n hÃ³a dá»¯ liá»‡u (Ä‘Ã£ Ä‘Æ°á»£c tá»± Ä‘á»™ng xá»­ lÃ½ trong code)
- âœ… Kiá»ƒm tra khÃ´ng cÃ³ file .npy corrupt
- âœ… Label pháº£i á»Ÿ dáº¡ng text tiáº¿ng Viá»‡t viáº¿t thÆ°á»ng

### 2. Training:

- âœ… **Báº¯t Ä‘áº§u vá»›i learning rate nhá»** (0.001) vÃ  giáº£m dáº§n
- âœ… **Sá»­ dá»¥ng GPU** Ä‘á»ƒ training nhanh hÆ¡n (Google Colab cung cáº¥p free GPU)
- âœ… **Monitor validation loss** Ä‘á»ƒ phÃ¡t hiá»‡n overfitting sá»›m
- âœ… **Save checkpoints thÆ°á»ng xuyÃªn** (Ä‘Ã£ tá»± Ä‘á»™ng)
- âœ… **Teacher forcing ratio giáº£m dáº§n** theo epochs (Ä‘Ã£ tá»± Ä‘á»™ng)

### 3. Overfitting:

Náº¿u tháº¥y overfitting (val_loss tÄƒng mÃ  train_loss giáº£m):
- TÄƒng `DROPOUT_RATE` (0.3 â†’ 0.5)
- TÄƒng data augmentation `AUGMENTATION_PROB` (0.3 â†’ 0.5)
- Giáº£m model size (sá»‘ filters, LSTM units)
- Thu tháº­p thÃªm dá»¯ liá»‡u training

### 4. Underfitting:

Náº¿u cáº£ train vÃ  val loss Ä‘á»u cao:
- TÄƒng model capacity (sá»‘ layers, hidden dims)
- Giáº£m dropout
- TÄƒng sá»‘ epochs
- Kiá»ƒm tra learning rate (cÃ³ thá»ƒ quÃ¡ cao hoáº·c quÃ¡ tháº¥p)

### 5. Cáº£i Thiá»‡n Performance:

- ğŸ“ˆ **Thu tháº­p thÃªm dá»¯ liá»‡u**: CÃ ng nhiá»u cÃ ng tá»‘t
- ğŸ¯ **Balance dataset**: Äáº£m báº£o cÃ¡c class cÃ³ sá»‘ lÆ°á»£ng sample tÆ°Æ¡ng Ä‘Æ°Æ¡ng
- ğŸ”§ **Hyperparameter tuning**: Thá»­ cÃ¡c giÃ¡ trá»‹ khÃ¡c
- ğŸ—ï¸ **Thá»­ Transformer**: Náº¿u cÃ³ Ä‘á»§ dá»¯ liá»‡u (>10k samples)
- ğŸ­ **Ensemble models**: Káº¿t há»£p nhiá»u models

### 6. Inference:

- âœ… Sá»­ dá»¥ng `best_model.pt` thay vÃ¬ `latest_checkpoint.pt`
- âœ… Set `max_length` phÃ¹ há»£p vá»›i Ä‘á»™ dÃ i trung bÃ¬nh cá»§a cÃ¢u
- âœ… Pre-process video giá»‘ng nhÆ° training data
- âœ… Batch prediction nhanh hÆ¡n single prediction

## ğŸ› Troubleshooting

### Lá»—i CUDA Out of Memory:

```bash
# Giáº£m batch size
python train.py --batch_size 8

# Hoáº·c giáº£m max_sequence_length trong config.py
MAX_SEQUENCE_LENGTH = 100  # thay vÃ¬ 150
```

### Lá»—i file khÃ´ng tá»“n táº¡i:

```bash
# Kiá»ƒm tra Ä‘Æ°á»ng dáº«n trong meta.csv
# Äáº£m báº£o Google Drive Ä‘Ã£ mount
```

### Model khÃ´ng há»c (loss khÃ´ng giáº£m):

```bash
# Thá»­ learning rate khÃ¡c
python train.py --learning_rate 0.0001

# Hoáº·c kiá»ƒm tra dá»¯ liá»‡u cÃ³ Ä‘Ãºng khÃ´ng
```

### BLEU score tháº¥p:

- Kiá»ƒm tra tokenization cÃ³ Ä‘Ãºng khÃ´ng
- Äáº£m báº£o vocabulary Ä‘á»§ lá»›n
- Train thÃªm epochs
- TÄƒng model capacity

## ğŸ“ Files Trong Project

```
sign2vn/
â”œâ”€â”€ config.py              # Cáº¥u hÃ¬nh toÃ n bá»™ project
â”œâ”€â”€ data_loader.py         # Data loading vÃ  preprocessing
â”œâ”€â”€ model.py              # Model architecture
â”œâ”€â”€ trainer.py            # Training logic
â”œâ”€â”€ train.py              # Main training script
â”œâ”€â”€ inference.py          # Inference script
â”œâ”€â”€ requirements.txt      # Dependencies
â”œâ”€â”€ Sign2VN_Training.ipynb  # Colab notebook
â””â”€â”€ README.md            # File nÃ y
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ“§ Contact

Náº¿u cÃ³ cÃ¢u há»i hoáº·c váº¥n Ä‘á», vui lÃ²ng táº¡o issue trÃªn GitHub.

---

**Happy Training! ğŸš€**
